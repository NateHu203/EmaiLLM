{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from typing import List\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "def setup_client():\n",
    "    \"\"\"\n",
    "    setting up the client for google genai\n",
    "    \"\"\"\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not GOOGLE_API_KEY:\n",
    "        print(\"GOOGLE_API_KEY is not set. Please set it in your environment.\")\n",
    "        sys.exit(1)\n",
    "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = setup_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(client, content, instruction, model=\"gemini-2.0-flash\"):\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=[content], # here should the content of email be\n",
    "        config=types.GenerateContentConfig(\n",
    "            max_output_tokens=1024,\n",
    "            temperature=0.1,\n",
    "            system_instruction= instruction,\n",
    "        )\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def keyword_preprocessing(keywords: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Preprocess the user-defined keywords into a list\n",
    "    \"\"\"\n",
    "    return [keyword.strip() for keyword in keywords.lower().split(\",\")]\n",
    "\n",
    "def retrieve_user_keywords():\n",
    "    \"\"\"\n",
    "    Retrieve user-defined keywords from the environment variable\n",
    "    \"\"\"\n",
    "    keywords = os.getenv(\"USER_KEYWORDS\")\n",
    "    if not keywords:\n",
    "        print(\"USER_KEYWORDS is not set. Please set it in your environment.\")\n",
    "        sys.exit(1)\n",
    "    return keyword_preprocessing(keywords)\n",
    "\n",
    "\n",
    "def classify_email(email_content: str, keywords: List[str], client):\n",
    "    KEYWORDS = \", \".join(keywords)\n",
    "\n",
    "    PROMPT_CLASSIFICATION = f\"\"\"\n",
    "    You are an email classification assistant. Your task is to analyze the content of emails and categorize them based on the following user-defined keywords:\n",
    "\n",
    "    [{KEYWORDS}] \n",
    "    \n",
    "    Example:\n",
    "    - Urgent: emergency, asap, immediate, critical, deadline\n",
    "    - Marketing: promotion, discount, offer, campaign, subscribe\n",
    "    - Technical: error, bug, issue, troubleshoot, support\n",
    "    - Personal: family, holiday, birthday, congratulations, weekend\n",
    "\n",
    "    Instructions:\n",
    "    1. Analyze the full email content provided\n",
    "    2. Identify any keywords that match the predefined categories\n",
    "    3. Classify the email into the most appropriate category\n",
    "    4. If multiple categories apply, report them all\n",
    "    5. If no keywords match, classify as \"General\" \n",
    "\n",
    "    Return your classification in this format:\n",
    "    CATEGORY: <determined categories (seperated by commas)>\n",
    "    CONFIDENCE: <high/medium/low based on keyword density>\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    User Keywords: Urgent, Marketing, Technical, Personal\n",
    "    \n",
    "    Email Content:\n",
    "    Greetings,\n",
    "    \n",
    "    This is the newsletter for this week. We have a special promotion for our loyal customers. Don't miss out on the discount offer!\n",
    "    We also have a emergency announcement regarding a critical issue with our service.\n",
    "    Please check your inbox for more details.\n",
    "    Thank you!\n",
    "    \n",
    "    Output:\n",
    "    CATEGORY: Urgent, Marketing\n",
    "    CONFIDENCE: high\n",
    "    \n",
    "\n",
    "    Do not include any additional explanation or analysis in your response.\n",
    "    \"\"\"\n",
    "    response = call_llm(client, content=email_content,instruction = PROMPT_CLASSIFICATION, model=\"gemini-2.0-flash\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/natehu/Desktop/QTM 329 Comp Ling/EmaiLLM/data/qtm_emails.json', 'r') as file:\n",
    "    email_data = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "# Load spaCy's English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess_email(email_text):\n",
    "    # Convert emails to lower case\n",
    "    email_text = email_text.lower()\n",
    "    \n",
    "    # Tokenize the email text\n",
    "    doc = nlp(email_text)\n",
    "    \n",
    "    # Lemmatize, remove stopwords, and punctuation\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc if token.text not in STOP_WORDS and token.text not in string.punctuation]\n",
    "    \n",
    "    # Join the lemmatized tokens back into a string\n",
    "    processed_text = \" \".join(lemmatized_tokens)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['networking', 'internship', 'job fair', 'interview']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_keyword = retrieve_user_keywords()\n",
    "user_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [0,24,44,65,123]\n",
    "output = []\n",
    "\n",
    "for i in index:\n",
    "    email = email_data[i]['content']\n",
    "    email = preprocess_email(email)\n",
    "    result = classify_email(email, user_keyword, client)\n",
    "    output.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CATEGORY: networking, internship\\nCONFIDENCE: high\\n',\n",
       " 'CATEGORY: internship\\nCONFIDENCE: high\\n',\n",
       " 'CATEGORY: networking\\nCONFIDENCE: medium\\n',\n",
       " 'CATEGORY: internship\\nCONFIDENCE: high\\n',\n",
       " 'CATEGORY: networking\\nCONFIDENCE: medium\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECIAL ANNOUNCMENT FROM THE BIOLOGY DEPARTMENT\n",
      " \n",
      " \n",
      "Are you a QSS-BIO major, or considering the QSS-BIO track?\n",
      " \n",
      "Come this Friday afternoon (3:30 PM)  in the QTM Department – room PAIS 561 conference room  on the 5th floor \n",
      " \n",
      "- to meet fellow QSS-BIO majors over pizza!\n",
      " \n",
      "This student-led event is a great opportunity to meet others in your track and hear about their experiences and plans. \n",
      " \n",
      "More details, GroupMe and RSVP links in the attached flyer.\n",
      " \n",
      "Hope to see you there,\n",
      "The QSS-BIO club\n",
      " \n",
      "See attached flyer for details \n",
      " \n",
      "Sadie Hannans\n",
      "Undergraduate Program Coordinator\n",
      "Department of Quantitative Theory & Methods\n",
      "Emory University\n",
      "Email: shanna9@emory.edu | 470-620-7981\n",
      "(she/her/hers)\n"
     ]
    }
   ],
   "source": [
    "print(email_data[44]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(email_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_filtered_130 = email_data[:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store two set of emails half and half and store as json\n",
    "emailGroup1 = email_filtered_130[:65]\n",
    "emailGroup2 = email_filtered_130[65:]\n",
    "with open('/Users/natehu/Desktop/QTM 329 Comp Ling/EmaiLLM/data/emailGroup1.json', 'w') as f:\n",
    "    json.dump(emailGroup1, f, indent=4)\n",
    "with open('/Users/natehu/Desktop/QTM 329 Comp Ling/EmaiLLM/data/emailGroup2.json', 'w') as f:\n",
    "    json.dump(emailGroup2, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
